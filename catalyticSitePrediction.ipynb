{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Zeal Jinwala  <br> \n",
    "Date: June 16, 2022  <br> \n",
    "Data Source: The dataset (courtesy of Natalia Petrova) is a subset of the data used in \"Prediction of catalytic residues using Support Vector Machine with selected protein sequence and structural properties\", Natalia Petrova and Cathy Wu, 2006. \n",
    "http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-312\n",
    "Please review that publication to learn more about this dataset and the catalytic residue prediction problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load catasite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1', '+1',\n",
       "       '+1', '+1', '+1', '+1', '+1', '+1', '+1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1',\n",
       "       '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arff.loadarff('NataliaPetrova.catsite.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['AAName1LetterCode'] = df['AAName1LetterCode'].apply(lambda x: x.decode(\"utf-8\"))\n",
    "df['class'] = df['class'].apply(lambda x: x.decode(\"utf-8\"))\n",
    "# not gonna need it but fancy code\n",
    "    # needs a dictionary aa2int for all amino acids\n",
    "    # AAName1LetterCode = df['AAName1LetterCode'].values\n",
    "    # intAA = list(map(lambda x:aa2int[x],AAName1LetterCode))\n",
    "aaOneHot = pd.DataFrame([ProteinAnalysis(i).count_amino_acids() for i in df['AAName1LetterCode']])\n",
    "df1 = df[['nearest_cleft_SA_area','nearest_cleft_distance','distance_to_3_largest_clefts','HB_main_chain_protein','ScoreConsScore','class']]\n",
    "result = pd.concat([aaOneHot, df1], axis=1, join=\"inner\")\n",
    "\n",
    "X = result.dropna()\n",
    "T = X['class'].values\n",
    "# X = result.iloc[:,0:25]\n",
    "X.pop('class')\n",
    "names = result.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a network for classification using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\\n            ...\\n            501, 502, 503, 504, 505, 506, 507, 508, 509, 510],\\n           dtype='int64', length=383)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g8/824tqwk50c17j0sh1y69p4z5x108l_/T/ipykernel_94967/2788951349.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print(len(X_train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# print(len(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\\n            ...\\n            501, 502, 503, 504, 505, 506, 507, 508, 509, 510],\\n           dtype='int64', length=383)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    # print(len(X_train))\n",
    "    # print(len(X_test))\n",
    "    y_train, y_test = T[train_index], T[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        1.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        6.571430e+02, 0.000000e+00, 0.000000e+00, 2.000000e+00,\n",
       "        6.950000e-01],\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        1.200658e+03, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
       "        9.010000e-01],\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        1.200658e+03, 0.000000e+00, 0.000000e+00, 2.000000e+00,\n",
       "        8.900000e-01],\n",
       "       [0.000000e+00, 1.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        1.200658e+03, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        9.100000e-01],\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
       "        6.791650e+02, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'K'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g8/824tqwk50c17j0sh1y69p4z5x108l_/T/ipykernel_94967/251750049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#     - Implement backward propagation to get the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#     - Update parameters (gradient descent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# define the keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'K'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural network model\n",
    "    # 1. Define the neural network structure ( # of input units,  # of hidden units, etc). \n",
    "    # 2. Initialize the model's parameters\n",
    "    # 3. Loop:\n",
    "    #     - Implement forward propagation\n",
    "    #     - Compute loss\n",
    "    #     - Implement backward propagation to get the gradients\n",
    "    #     - Update parameters (gradient descent)\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, T, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, T)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a network for classification using a subset of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the average training accuracy across all repetitions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Report the average test accuracy across all repetitions."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
